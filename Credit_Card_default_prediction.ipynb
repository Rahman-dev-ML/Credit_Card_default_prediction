{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "36GNpzh6HqJ4"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# You have to include the full link to the csv file containing your dataset\n",
        "creditcard_df = pd.read_csv('UCI_Credit_Card.csv')\n"
      ],
      "metadata": {
        "id": "iLoBmIqKHyTr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "creditcard_df"
      ],
      "metadata": {
        "id": "loTB-vWPHzzy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "creditcard_df.info()\n",
        "# 24 features in total, each contains 30000 data points"
      ],
      "metadata": {
        "id": "zS4whRpUH1DM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "creditcard_df.describe()\n",
        "# the mean for LIMIT_BAL = 1500, min =1, and max = 30000\n",
        "# the mean for AGE = 25 years old, min = 21, and max = 79\n",
        "# PAY_AMT average is around 5k"
      ],
      "metadata": {
        "id": "sexp3TNXH2tr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Let's see if we have any missing data, luckily we don't!\n",
        "sns.heatmap(creditcard_df.isnull(), yticklabels = False, cbar = False, cmap=\"Blues\")\n"
      ],
      "metadata": {
        "id": "tGLzccvZH5td"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "creditcard_df.hist(bins = 30, figsize = (20,20), color = 'r')\n"
      ],
      "metadata": {
        "id": "9eDc--pGH7Gm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Let's drop the ID column\n",
        "creditcard_df.drop(['ID'], axis=1, inplace=True)"
      ],
      "metadata": {
        "id": "eRz6cJ9UH8iZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Let's see how many customers could potentially default on their credit card payment!\n",
        "cc_default_df        = creditcard_df[creditcard_df['default.payment.next.month'] == 1]\n",
        "cc_nodefault_df      = creditcard_df[creditcard_df['default.payment.next.month'] == 0]\n"
      ],
      "metadata": {
        "id": "M9ksu2aqH-pf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Count the number of employees who stayed and left\n",
        "# It seems that we are dealing with an imbalanced dataset\n",
        "\n",
        "print(\"Total =\", len(creditcard_df))\n",
        "\n",
        "print(\"Number of customers who defaulted on their credit card payments =\", len(cc_default_df))\n",
        "print(\"Percentage of customers who defaulted on their credit card payments =\", 1.*len(cc_default_df)/len(creditcard_df)*100.0, \"%\")\n",
        "\n",
        "print(\"Number of customers who did not default on their credit card payments (paid their balance)=\", len(cc_nodefault_df))\n",
        "print(\"Percentage of customers who did not default on their credit card payments (paid their balance)=\", 1.*len(cc_nodefault_df)/len(creditcard_df)*100.0, \"%\")"
      ],
      "metadata": {
        "id": "MK-w_LSWIAIf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Let's compare the mean and std of the customers who stayed and left\n",
        "cc_default_df.describe()"
      ],
      "metadata": {
        "id": "msXIwr7MIB6H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Let's compare the mean and std of the customers who stayed and left\n",
        "cc_nodefault_df.describe()"
      ],
      "metadata": {
        "id": "Km5AhTo2IEZ3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "correlations = creditcard_df.corr()\n",
        "f, ax = plt.subplots(figsize = (20, 20))\n",
        "sns.heatmap(correlations, annot = True)\n"
      ],
      "metadata": {
        "id": "cLQlYBDHIF1A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=[20,20])\n",
        "plt.subplot(311)\n",
        "sns.countplot(x = 'EDUCATION', hue = 'default.payment.next.month', data = creditcard_df)\n",
        "plt.subplot(312)\n",
        "sns.countplot(x = 'SEX', hue = 'default.payment.next.month', data = creditcard_df)\n",
        "plt.subplot(313)\n",
        "sns.countplot(x = 'MARRIAGE', hue = 'default.payment.next.month', data = creditcard_df)\n"
      ],
      "metadata": {
        "id": "Y5gCltewIImx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "plt.figure(figsize=(12,7))\n",
        "\n",
        "sns.distplot(cc_nodefault_df['LIMIT_BAL'], bins = 250, color = 'r')\n",
        "sns.distplot(cc_default_df['LIMIT_BAL'], bins = 250, color = 'b')\n",
        "\n",
        "plt.xlabel('Amount of bill statement in September, 2005 (NT dollar)')\n",
        "#plt.xlim(0, 200000)\n"
      ],
      "metadata": {
        "id": "9xHSR89JIK24"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(12,7))\n",
        "\n",
        "sns.kdeplot(cc_nodefault_df['BILL_AMT1'], label = 'Customers who did not default (paid balance)', shade = True, color = 'r')\n",
        "sns.kdeplot(cc_default_df['BILL_AMT1'], label = 'Customers who defaulted (did not pay balance)', shade = True, color = 'b')\n",
        "\n",
        "plt.xlabel('Amount of bill statement in September, 2005 (NT dollar)')\n",
        "#plt.xlim(0, 200000)"
      ],
      "metadata": {
        "id": "a3Yw2D20IN06"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(12,7))\n",
        "\n",
        "sns.kdeplot(cc_nodefault_df['PAY_AMT1'], label = 'Customers who did not default (paid balance)', shade = True, color = 'r')\n",
        "sns.kdeplot(cc_default_df['PAY_AMT1'], label = 'Customers who defaulted (did not pay balance)', shade = True, color = 'b')\n",
        "\n",
        "plt.xlabel('PAY_AMT1: Amount of previous payment in September, 2005 (NT dollar)')\n",
        "plt.xlim(0, 200000)"
      ],
      "metadata": {
        "id": "UnrhoipKIPr9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "plt.figure(figsize=[10,20])\n",
        "plt.subplot(211)\n",
        "sns.boxplot(x = 'SEX', y = 'LIMIT_BAL', data = creditcard_df, showfliers = False)\n",
        "plt.subplot(212)\n",
        "sns.boxplot(x = 'SEX', y = 'LIMIT_BAL', data = creditcard_df)"
      ],
      "metadata": {
        "id": "8wLHi8vYIRgs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=[10,20])\n",
        "plt.subplot(211)\n",
        "sns.boxplot(x = 'MARRIAGE', y = 'LIMIT_BAL', data = creditcard_df, showfliers = False)\n",
        "plt.subplot(212)\n",
        "sns.boxplot(x = 'MARRIAGE', y = 'LIMIT_BAL', data = creditcard_df)\n"
      ],
      "metadata": {
        "id": "tr6ANqRFITVF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_cat = creditcard_df[['SEX', 'EDUCATION', 'MARRIAGE']]\n",
        "X_cat"
      ],
      "metadata": {
        "id": "d46ZDarzIVQ7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import OneHotEncoder\n",
        "onehotencoder = OneHotEncoder()\n",
        "X_cat = onehotencoder.fit_transform(X_cat).toarray()"
      ],
      "metadata": {
        "id": "FJlC4usaIYJ9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_cat.shape\n",
        "X_cat = pd.DataFrame(X_cat)"
      ],
      "metadata": {
        "id": "H8BESHObIZkA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# note that we dropped the target 'default.payment.next.month'\n",
        "X_numerical = creditcard_df[['LIMIT_BAL', 'AGE', 'PAY_0', 'PAY_2', 'PAY_3', 'PAY_4', 'PAY_5', 'PAY_6',\n",
        "                'BILL_AMT1','BILL_AMT2', 'BILL_AMT3', 'BILL_AMT4', 'BILL_AMT5', 'BILL_AMT6',\n",
        "                'PAY_AMT1', 'PAY_AMT2', 'PAY_AMT3', 'PAY_AMT4', 'PAY_AMT5', 'PAY_AMT6']]\n",
        "X_numerical"
      ],
      "metadata": {
        "id": "qQXhD5Z6IdmB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_all = pd.concat([X_cat, X_numerical], axis = 1)\n",
        "X_all"
      ],
      "metadata": {
        "id": "LeFUQ-fnIfoo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import MinMaxScaler\n",
        "scaler = MinMaxScaler()\n",
        "X = scaler.fit_transform(X_all)"
      ],
      "metadata": {
        "id": "DaiBrjPZIhR5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y = creditcard_df['default.payment.next.month']\n",
        "y"
      ],
      "metadata": {
        "id": "Rnt5s0_AIjLO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#APPLYING XGBOOST"
      ],
      "metadata": {
        "id": "tjzhrmt5Ikir"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.25)"
      ],
      "metadata": {
        "id": "S5e6NHI3IobW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install xgboost"
      ],
      "metadata": {
        "id": "Vzd4J5jqIp9u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train an XGBoost regressor model\n",
        "\n",
        "import xgboost as xgb\n",
        "\n",
        "\n",
        "model = xgb.XGBClassifier(objective ='reg:squarederror', learning_rate = 0.1, max_depth = 5, n_estimators = 100)\n",
        "\n",
        "model.fit(X_train, y_train)"
      ],
      "metadata": {
        "id": "3k01VgrhIrlv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "y_pred = model.predict(X_test)\n"
      ],
      "metadata": {
        "id": "YEb_BaiFItgL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred"
      ],
      "metadata": {
        "id": "MH9fqcUUIvA8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "\n",
        "print(\"Accuracy {} %\".format( 100 * accuracy_score(y_pred, y_test)))"
      ],
      "metadata": {
        "id": "GMUojo8SIwiC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(classification_report(y_test, y_pred))"
      ],
      "metadata": {
        "id": "1Ot5GiS-IyFZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "param_grid = {\n",
        "        'gamma': [0.5, 1, 5],   # regularization parameter\n",
        "        'subsample': [0.6, 0.8, 1.0], # % of rows taken to build each tree\n",
        "        'colsample_bytree': [0.6, 0.8, 1.0], # number of columns used by each tree\n",
        "        'max_depth': [3, 4, 5] # depth of each tree\n",
        "        }"
      ],
      "metadata": {
        "id": "KKA6VPqxI0J_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from xgboost import XGBClassifier\n",
        "\n",
        "xgb_model = XGBClassifier(learning_rate=0.01, n_estimators=100, objective='binary:logistic')\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "grid = GridSearchCV(xgb_model, param_grid, refit = True, verbose = 4)\n",
        "grid.fit(X_train, y_train)"
      ],
      "metadata": {
        "id": "rq56_tLzI1ml"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_predict_optim = grid.predict(X_test)"
      ],
      "metadata": {
        "id": "TueE7LHtI3Ad"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_predict_optim"
      ],
      "metadata": {
        "id": "hgWNJs8bI49R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(classification_report(y_test, y_predict_optim))"
      ],
      "metadata": {
        "id": "QfuBr4g7I6hO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#XG BOOST ON AMAZON SAGEMAKER"
      ],
      "metadata": {
        "id": "eN00z8mdI9Jk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert the array into dataframe in a way that target variable is set as the first column and followed by feature columns\n",
        "# This is because sagemaker built-in algorithm expects the data in this format.\n",
        "\n",
        "train_data = pd.DataFrame({'Target': y_train[:,0]})\n",
        "for i in range(X_train.shape[1]):\n",
        "    train_data[i] = X_train[:,i]\n",
        " train_data.head()"
      ],
      "metadata": {
        "id": "uz1XepjoJHPD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "val_data = pd.DataFrame({'Target':y_val[:,0]})\n",
        "for i in range(X_val.shape[1]):\n",
        "    val_data[i] = X_val[:,i]"
      ],
      "metadata": {
        "id": "bXq-2RY1KJjk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "val_data.head()"
      ],
      "metadata": {
        "id": "2qwM15DsKLVx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "val_data.shape"
      ],
      "metadata": {
        "id": "CrOuZUBpKNjv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# save train_data and validation_data as csv files.\n",
        "\n",
        "train_data.to_csv('train.csv', header = False, index = False)\n",
        "val_data.to_csv('validation.csv', header = False, index = False)"
      ],
      "metadata": {
        "id": "9DHi0DYtKPaP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Boto3 allows Python developer to write software that makes use of services like Amazon S3 and Amazon EC2\n",
        "\n",
        "import sagemaker\n",
        "import boto3\n",
        "\n",
        "# Create a sagemaker session\n",
        "sagemaker_session = sagemaker.Session()\n",
        "\n",
        "#S 3 bucket and prefix that we want to use\n",
        "# default_bucket - creates a Amazon S3 bucket to be used in this session\n",
        "bucket = 'sagemaker-practical-3'\n",
        "prefix = 'XGBoost-Regressor'\n",
        "key = 'XGBoost-Regressor'\n",
        "#Roles give learning and hosting access to the data\n",
        "#This is specified while opening the sagemakers instance in \"Create an IAM role\"\n",
        "role = sagemaker.get_execution_role()"
      ],
      "metadata": {
        "id": "qI9_Yvh8KQ1v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(role)"
      ],
      "metadata": {
        "id": "HVcckMItKT0q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# read the data from csv file and then upload the data to s3 bucket\n",
        "import os\n",
        "with open('train.csv','rb') as f:\n",
        "    # The following code uploads the data into S3 bucket to be accessed later for training\n",
        "    boto3.Session().resource('s3').Bucket(bucket).Object(os.path.join(prefix, 'train', key)).upload_fileobj(f)\n",
        "\n",
        "# Let's print out the training data location in s3\n",
        "s3_train_data = 's3://{}/{}/train/{}'.format(bucket, prefix, key)\n",
        "print('uploaded training data location: {}'.format(s3_train_data))"
      ],
      "metadata": {
        "id": "frziXV2DKVg0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# read the data from csv file and then upload the data to s3 bucket\n",
        "\n",
        "with open('validation.csv','rb') as f:\n",
        "    # The following code uploads the data into S3 bucket to be accessed later for training\n",
        "\n",
        "    boto3.Session().resource('s3').Bucket(bucket).Object(os.path.join(prefix, 'validation', key)).upload_fileobj(f)\n",
        "# Let's print out the validation data location in s3\n",
        "s3_validation_data = 's3://{}/{}/validation/{}'.format(bucket, prefix, key)\n",
        "print('uploaded validation data location: {}'.format(s3_validation_data))"
      ],
      "metadata": {
        "id": "NaYtXoMQKW_Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# creates output placeholder in S3 bucket to store the output\n",
        "\n",
        "output_location = 's3://{}/{}/output'.format(bucket, prefix)\n",
        "print('training artifacts will be uploaded to: {}'.format(output_location))"
      ],
      "metadata": {
        "id": "tUHXNUtCKYx7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# This code is used to get the training container of sagemaker built-in algorithms\n",
        "\n",
        "\n",
        "from sagemaker.amazon.amazon_estimator import get_image_uri\n",
        "\n",
        "container = get_image_uri(boto3.Session().region_name, 'xgboost','0.90-2') # Latest version of XGboost"
      ],
      "metadata": {
        "id": "uL7cxEGoKadi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Specify the type of instance that we would like to use for training\n",
        "# output path and sagemaker session into the Estimator.\n",
        "# We can also specify how many instances we would like to use for training\n",
        "\n",
        "# Recall that XGBoost works by combining an ensemble of weak models to generate accurate/robust results.\n",
        "# The weak models are randomized to avoid overfitting\n",
        "\n",
        "# num_round: The number of rounds to run the training.\n",
        "\n",
        "\n",
        "# Alpha: L1 regularization term on weights. Increasing this value makes models more conservative.\n",
        "\n",
        "# colsample_by_tree: fraction of features that will be used to train each tree.\n",
        "\n",
        "# eta: Step size shrinkage used in updates to prevent overfitting.\n",
        "# After each boosting step, eta parameter shrinks the feature weights to make the boosting process more conservative.\n",
        "\n",
        "\n",
        "Xgboost_regressor1 = sagemaker.estimator.Estimator(container,\n",
        "                                       role,\n",
        "                                       train_instance_count = 1,\n",
        "                                       train_instance_type = 'ml.m5.2xlarge',\n",
        "                                       output_path = output_location,\n",
        "                                       sagemaker_session = sagemaker_session)\n",
        "\n",
        "#We can tune the hyper-parameters to improve the performance of the model\n",
        "\n",
        "Xgboost_regressor1.set_hyperparameters(max_depth = 10,\n",
        "                           objective = 'reg:linear',\n",
        "                           colsample_bytree = 0.3,\n",
        "                           alpha = 10,\n",
        "                           eta = 0.1,\n",
        "                           num_round = 100\n",
        "                           )\n",
        "\n"
      ],
      "metadata": {
        "id": "d-XgWS_tKcls"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating \"train\", \"validation\" channels to feed in the model\n",
        "# Source: https://docs.aws.amazon.com/sagemaker/latest/dg/sagemaker-algo-docker-registry-paths.html\n",
        "\n",
        "train_input = sagemaker.session.s3_input(s3_data = s3_train_data, content_type='csv',s3_data_type = 'S3Prefix')\n",
        "valid_input = sagemaker.session.s3_input(s3_data = s3_validation_data, content_type='csv',s3_data_type = 'S3Prefix')\n",
        "\n",
        "\n",
        "data_channels = {'train': train_input,'validation': valid_input}\n",
        "\n",
        "\n",
        "Xgboost_regressor1.fit(data_channels)"
      ],
      "metadata": {
        "id": "_z5ccYu8KjkM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Deploy the model to perform inference\n",
        "\n",
        "Xgboost_regressor = Xgboost_regressor1.deploy(initial_instance_count = 1, instance_type = 'ml.m5.2xlarge')"
      ],
      "metadata": {
        "id": "v6MRu_aGKk_u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "Content type over-rides the data that will be passed to the deployed model, since the deployed model expects data\n",
        "in text/csv format, we specify this as content -type.\n",
        "\n",
        "Serializer accepts a single argument, the input data, and returns a sequence of bytes in the specified content\n",
        "type\n",
        "\n",
        "Reference: https://sagemaker.readthedocs.io/en/stable/predictors.html\n",
        "'''\n",
        "from sagemaker.predictor import csv_serializer, json_deserializer\n",
        "\n",
        "Xgboost_regressor.content_type = 'text/csv'\n",
        "Xgboost_regressor.serializer = csv_serializer\n",
        "Xgboost_regressor.deserializer = None"
      ],
      "metadata": {
        "id": "d2LHrqnrKmV0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_test.shape"
      ],
      "metadata": {
        "id": "F-QNDiVSKnrm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# making prediction\n",
        "\n",
        "predictions1 = Xgboost_regressor.predict(X_test[0:10000])\n",
        "predictions2 = Xgboost_regressor.predict(X_test[10000:20000])\n",
        "predictions3 = Xgboost_regressor.predict(X_test[20000:30000])\n",
        "predictions4 = Xgboost_regressor.predict(X_test[30000:31618])"
      ],
      "metadata": {
        "id": "Ut5BunovLQE5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# custom code to convert the values in bytes format to array\n",
        "\n",
        "def bytes_2_array(x):\n",
        "\n",
        "    # makes entire prediction as string and splits based on ','\n",
        "    l = str(x).split(',')\n",
        "\n",
        "    # Since the first element contains unwanted characters like (b,',') we remove them\n",
        "    l[0] = l[0][2:]\n",
        "    #same-thing as above remove the unwanted last character (')\n",
        "    l[-1] = l[-1][:-1]\n",
        "\n",
        "    # iterating through the list of strings and converting them into float type\n",
        "    for i in range(len(l)):\n",
        "        l[i] = float(l[i])\n",
        "\n",
        "    # converting the list into array\n",
        "    l = np.array(l).astype('float32')\n",
        "\n",
        "    # reshape one-dimensional array to two-dimensional array\n",
        "    return l.reshape(-1,1)"
      ],
      "metadata": {
        "id": "eQ2ZyUEhLV5S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predicted_values_1 = bytes_2_array(predictions1)"
      ],
      "metadata": {
        "id": "RSIVreugLXnt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predicted_values_1.shape"
      ],
      "metadata": {
        "id": "9QL949z2LY9-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predicted_values_2 = bytes_2_array(predictions2)\n",
        "predicted_values_2.shape"
      ],
      "metadata": {
        "id": "kghU_QF9LaSN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predicted_values_3 = bytes_2_array(predictions3)\n",
        "predicted_values_3.shape"
      ],
      "metadata": {
        "id": "3jA5VXmbLbkt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predicted_values_4 = bytes_2_array(predictions4)\n",
        "predicted_values_4.shape"
      ],
      "metadata": {
        "id": "5j6PfwbwLc7x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predicted_values = np.concatenate((predicted_values_1, predicted_values_2, predicted_values_3, predicted_values_4))"
      ],
      "metadata": {
        "id": "VrImXHyMLeOf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predicted_values.shape"
      ],
      "metadata": {
        "id": "Yqx7eDVtLf9j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error\n",
        "from math import sqrt\n",
        "k = X_test.shape[1]\n",
        "n = len(X_test)\n",
        "RMSE = float(format(np.sqrt(mean_squared_error(y_test, predicted_values)),'.3f'))\n",
        "MSE = mean_squared_error(y_test, predicted_values)\n",
        "MAE = mean_absolute_error(y_test, predicted_values)\n",
        "r2 = r2_score(y_test, predicted_values)\n",
        "adj_r2 = 1-(1-r2)*(n-1)/(n-k-1)\n",
        "\n",
        "print('RMSE =',RMSE, '\\nMSE =',MSE, '\\nMAE =',MAE, '\\nR2 =', r2, '\\nAdjusted R2 =', adj_r2)"
      ],
      "metadata": {
        "id": "dBpzJ4swLhWX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Delete the end-point\n",
        "\n",
        "Xgboost_regressor.delete_endpoint()"
      ],
      "metadata": {
        "id": "o4bQGyFGLjK5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "XkeKMxiqLRk1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "L0ALYC9cKcpI"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}